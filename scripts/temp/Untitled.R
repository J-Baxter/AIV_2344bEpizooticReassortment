functions {
  /* integer sequence of values
  * Args:
    *   start: starting integer
  *   end: ending integer
  * Returns:
    *   an integer sequence from start to end
  */
    array[] int sequence(int start, int end) {
      array[end - start + 1] int seq;
      for (n in 1:num_elements(seq)) {
        seq[n] = n + start - 1;
      }
      return seq;
    }
  /* compute correlated group-level effects
  * Args:
    *   z: matrix of unscaled group-level effects
  *   SD: vector of standard deviation parameters
  *   L: cholesky factor correlation matrix
  * Returns:
    *   matrix of scaled group-level effects
  */
    matrix scale_r_cor(matrix z, vector SD, matrix L) {
      // r is stored in another dimension order than z
      return transpose(diag_pre_multiply(SD, L) * z);
    }
  // compute partial sums of the log-likelihood
  real partial_log_lik_lpmf(array[] int seq, int start, int end, data vector Y, data matrix X, vector b, data matrix X_shape, vector b_shape, data array[] int J_1, data vector Z_1_1, data vector Z_1_2, data vector Z_1_3, data vector Z_1_4, data vector Z_1_5, data vector Z_1_6, vector r_1_1, vector r_1_2, vector r_1_3, vector r_1_4, vector r_1_5, vector r_1_6, data array[] int J_2, data vector Z_2_1, vector r_2_1) {
    real ptarget = 0;
    int N = end - start + 1;
    // initialize linear predictor term
    vector[N] mu = rep_vector(0.0, N);
    // initialize linear predictor term
    vector[N] shape = rep_vector(0.0, N);
    mu += X[start:end] * b;
    shape += X_shape[start:end] * b_shape;
    for (n in 1:N) {
      // add more terms to the linear predictor
      int nn = n + start - 1;
      mu[n] += r_1_1[J_1[nn]] * Z_1_1[nn] + r_1_2[J_1[nn]] * Z_1_2[nn] + r_1_3[J_1[nn]] * Z_1_3[nn] + r_1_4[J_1[nn]] * Z_1_4[nn] + r_1_5[J_1[nn]] * Z_1_5[nn] + r_1_6[J_1[nn]] * Z_1_6[nn] + r_2_1[J_2[nn]] * Z_2_1[nn];
    }
    mu = exp(mu);
    shape = exp(shape);
    for (n in 1:N) {
      int nn = n + start - 1;
      ptarget += gamma_lpdf(Y[nn] | shape[n], shape[n] / mu[n]);
    }
    return ptarget;
  }
}
data {
  int<lower=1> N;  // total number of observations
  vector[N] Y;  // response variable
  int<lower=1> K;  // number of population-level effects
  matrix[N, K] X;  // population-level design matrix
  int<lower=1> K_shape;  // number of population-level effects
  matrix[N, K_shape] X_shape;  // population-level design matrix
  int grainsize;  // grainsize for threading
  // data for group-level effects of ID 1
  int<lower=1> N_1;  // number of grouping levels
  int<lower=1> M_1;  // number of coefficients per level
  array[N] int<lower=1> J_1;  // grouping indicator per observation
  // group-level predictor values
  vector[N] Z_1_1;
  vector[N] Z_1_2;
  vector[N] Z_1_3;
  vector[N] Z_1_4;
  vector[N] Z_1_5;
  vector[N] Z_1_6;
  int<lower=1> NC_1;  // number of group-level correlations
  // data for group-level effects of ID 2
  int<lower=1> N_2;  // number of grouping levels
  int<lower=1> M_2;  // number of coefficients per level
  array[N] int<lower=1> J_2;  // grouping indicator per observation
  // group-level predictor values
  vector[N] Z_2_1;
  int prior_only;  // should the likelihood be ignored?
}
transformed data {
  array[N] int seq = sequence(1, N);
}
parameters {
  vector[K] b;  // regression coefficients
  vector[K_shape] b_shape;  // regression coefficients
  vector<lower=0>[M_1] sd_1;  // group-level standard deviations
  matrix[M_1, N_1] z_1;  // standardized group-level effects
  cholesky_factor_corr[M_1] L_1;  // cholesky factor of correlation matrix
  vector<lower=0>[M_2] sd_2;  // group-level standard deviations
  array[M_2] vector[N_2] z_2;  // standardized group-level effects
}
transformed parameters {
  matrix[N_1, M_1] r_1;  // actual group-level effects
  // using vectors speeds up indexing in loops
  vector[N_1] r_1_1;
  vector[N_1] r_1_2;
  vector[N_1] r_1_3;
  vector[N_1] r_1_4;
  vector[N_1] r_1_5;
  vector[N_1] r_1_6;
  vector[N_2] r_2_1;  // actual group-level effects
  real lprior = 0;  // prior contributions to the log posterior
  // compute actual group-level effects
  r_1 = scale_r_cor(z_1, sd_1, L_1);
  r_1_1 = r_1[, 1];
  r_1_2 = r_1[, 2];
  r_1_3 = r_1[, 3];
  r_1_4 = r_1[, 4];
  r_1_5 = r_1[, 5];
  r_1_6 = r_1[, 6];
  r_2_1 = (sd_2[1] * (z_2[1]));
  lprior += normal_lpdf(b[1] | 13,1.5);
  lprior += normal_lpdf(b[2] | 13,2);
  lprior += normal_lpdf(b[3] | 12,1.5);
  lprior += normal_lpdf(b[4] | 13,1.5);
  lprior += normal_lpdf(b[5] | 0, 2);
  lprior += normal_lpdf(b[6] | 0, 2);
  lprior += normal_lpdf(b[7] | 0, 2);
  lprior += normal_lpdf(b[8] | 0, 2);
  lprior += normal_lpdf(b[9] | 0, 2);
  lprior += normal_lpdf(b[10] | 0, 2);
  lprior += normal_lpdf(b_shape | 0,2);
  lprior += exponential_lpdf(sd_1 | 0.5);
  lprior += lkj_corr_cholesky_lpdf(L_1 | 1);
  lprior += exponential_lpdf(sd_2 | 0.5);
}
model {
  // likelihood including constants
  if (!prior_only) {
    target += reduce_sum(partial_log_lik_lpmf, seq, grainsize, Y, X, b, X_shape, b_shape, J_1, Z_1_1, Z_1_2, Z_1_3, Z_1_4, Z_1_5, Z_1_6, r_1_1, r_1_2, r_1_3, r_1_4, r_1_5, r_1_6, J_2, Z_2_1, r_2_1);
  }
  // priors including constants
  target += lprior;
  target += std_normal_lpdf(to_vector(z_1));
  target += std_normal_lpdf(z_2[1]);
}
generated quantities {
  // compute group-level correlations
  corr_matrix[M_1] Cor_1 = multiply_lower_tri_self_transpose(L_1);
  vector<lower=-1,upper=1>[NC_1] cor_1;
  // extract upper diagonal of correlation matrix
  for (k in 1:M_1) {
    for (j in 1:(k - 1)) {
      cor_1[choose(k - 1, 2) + j] = Cor_1[j, k];
    }
  }
}